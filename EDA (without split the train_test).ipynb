{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Enalysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: \n",
    "- Import the Lybraries\n",
    "- Set the Directories\n",
    "- data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\\\DSBA\\\\Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"housing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: \n",
    "1. Check the Shape\n",
    "2. Check Head & Tail\n",
    "3. Check the Summary\n",
    "4. Check the information\n",
    "5. Check the duplicate values\n",
    "6. Check the missing Values and visualization\n",
    "7. Outliers visualization\n",
    "8. Devide in 2 subset: \n",
    "    -  (1) Numbers column\n",
    "    -  (2) Categorical column\n",
    "\n",
    "### 8.1) Numbers columns\n",
    " -   Data Cleaning:\n",
    "    - Missing values imputation - mean, median\n",
    "    - Missing values imputation - SimpleImputer\n",
    "\n",
    "- Feature Scaling: (outlier issues solved)\n",
    "     - Standardization\n",
    "     - Min-Max Scaling\n",
    "     - Normalization\n",
    "\n",
    "### 8.2) Categorical column\n",
    "-  Data Cleaning:\n",
    "    - Missing values imputation - Most frequent (Mode)\n",
    "-  Encoding: \n",
    "    - One Hot Encoding \n",
    "    - Ordinal Encoding\n",
    "\n",
    " ## 9. Concat the num & cat subset into Final dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\tCheck the Shape of df\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Head & Tail\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.  Check the Summary of df\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. heck the information\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Check the duplicate values\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Check the missing Values \n",
    "pd.DataFrame(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the rows which has missing values\n",
    "data[data.isnull().any(axis=1)].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Divide into 2 subset:\n",
    "   \t\t(7.1) Numbers column\n",
    "    \t(7.2) Categorical column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = data.select_dtypes(include=['number'])\n",
    "data_char = data.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (7.1) Numbers columns\n",
    "  - Data Cleaning\n",
    "  - Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tData Cleaning:\n",
    "- Check the Median values\n",
    "- Missing values visualization.\n",
    "- Missing values imputation - mean/median\n",
    "- Missing values imputation – SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the all numerical Columns name\n",
    "pd.DataFrame(data_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Median values\n",
    "pd.DataFrame(data_num.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Values Visualization \n",
    "import missingno as msno\n",
    "%matplotlib inline\n",
    "\n",
    "msno.matrix(data_num)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values imputation - mean / median\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X = imputer.fit_transform(data_num)\n",
    "data_num_trans = pd.DataFrame(X, columns=data_num.columns, index=data_num.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the missing values in numerical columns\n",
    "pd.DataFrame(data_num_trans.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After replace with median value, then check a NaN rows's values \n",
    "data_num_trans[\"total_bedrooms\"].iloc[696]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Remove rows \n",
    "# data_num_trans = data_num.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tFeature Scaling: (outlier issues solved)\n",
    "- Data distribution Check (plot: Histogram, boxplot)\n",
    "- Standardization\n",
    "- Min-Max Scaling\n",
    "- Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data distribution Check by Boxplot (finding Outliers / extream values)\n",
    "\n",
    "data_num_trans.plot(kind='box', subplots=True, layout=(len(data_num_impute.columns)//3 + 1, 3), figsize=(20, 15), sharex=False, sharey=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or,\n",
    "\n",
    "for i in data_num_trans.columns:\n",
    "    sns.boxplot(data= data_num_impute, x=i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data distribution Check by Histogram plot\n",
    "data_num_trans.hist(bins=50, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sdandardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "data_num_std_scaled = std_scaler.fit_transform(data_num_trans)\n",
    "\n",
    "\n",
    "data_num_std_scaled_df = pd.DataFrame (data_num_std_scaled, columns=data_num.columns, index=data_num.index)\n",
    "data_num_std_scaled_df.hist(bins=50, figsize=(20, 15))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num_std_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "data_num_min_max_scaled = min_max_scaler.fit_transform(data_num_trans)\n",
    "\n",
    "data_num_min_max_scaled_df = pd.DataFrame( data_num_min_max_scaled, columns=data_num.columns, index=data_num.index)\n",
    "data_num_min_max_scaled_df.hist(bins=50, figsize=(20, 15))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num_min_max_scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (7.2) Categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tData Cleaning:\n",
    "- Missing values imputation - Most frequent (Mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data.select_dtypes(include=['object'])\n",
    "data_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of all categorical columns \n",
    "data_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique item check\n",
    "pd.DataFrame(data_cat['ocean_proximity'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times each item has values\n",
    "for i in data_cat.columns:\n",
    "    print(data_cat[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the mode for all categorical columns\n",
    "import statistics\n",
    "data_char.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value check\n",
    "pd.DataFrame(data_char.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# (if there any missing values) ##############\n",
    "# Fill missing values in categorical columns with the mode\n",
    "\n",
    "# code: \n",
    "# data_char_filled = data_char.apply(lambda x: x.fillna(x.mode()[0]) if x.mode().size > 0 else x, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tEncoding: \n",
    "- One Hot Encoding \n",
    "- Ordinal Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "OHE = OneHotEncoder(sparse_output=False)\n",
    "data_Cat_OHE = OHE.fit_transform(data_cat)\n",
    "\n",
    "# Create the DataFrame with the correct column names\n",
    "encoded_columns = OHE.get_feature_names_out(data_cat.columns)\n",
    "data_cat_OHE_df = pd.DataFrame(data_Cat_OHE, columns=encoded_columns, index=data_cat.index)\n",
    "\n",
    "data_cat_OHE_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ (if we need Ordinal Encoding insteaD of One Hot Encoding) #############\n",
    "\n",
    "# Code: (in below)\n",
    "\n",
    "# from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# ordinal_encoder = OrdinalEncoder()\n",
    "# housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "\n",
    "# housing_cat_encoded_df = pd.DataFrame(housing_cat_encoded, columns=housing_cat.columns, index=housing_cat.index)\n",
    "\n",
    "# print(ordinal_encoder.categories_)\n",
    "\n",
    "# housing_cat_encoded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Concat the num & cat subset into Final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'housing_num' and 'housing_cat' are your DataFrames\n",
    "\n",
    "data_final = pd.concat([data_num_min_max_scaled_df, data_cat_OHE_df], axis=1)\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
